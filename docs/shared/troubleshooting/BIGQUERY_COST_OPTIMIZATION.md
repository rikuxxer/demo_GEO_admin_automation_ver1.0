# BigQueryコスト最適化ガイド

## 現状分析

### 現在のクエリパターン

#### 1. プロジェクト一覧取得 (`getProjects()`)
```sql
SELECT *
FROM `universegeo_dataset.projects`
ORDER BY COALESCE(_register_datetime, created_at, updated_at) DESC
```

**問題点**:
- `SELECT *` により全列をスキャン（不要な列も含む）
- 全件取得（ページネーションなし）
- 案件が増えるとスキャン量が線形に増加

**想定スキャン量**:
- 現在（100案件）: 約0.2MB/クエリ
- 1年後（3,600案件）: 約7.2MB/クエリ
- 3年後（10,800案件）: 約21.6MB/クエリ

#### 2. セグメント取得 (`getSegments()`)
```sql
SELECT *
FROM `universegeo_dataset.segments`
ORDER BY ...
```

**問題点**: 同様に`SELECT *`で全列スキャン

#### 3. POI取得 (`getPois()`, `getPoisByProject()`)
```sql
SELECT *
FROM `universegeo_dataset.pois`
WHERE project_id = @project_id
```

**問題点**:
- POIテーブルは最も大きくなる（1案件あたり1,000地点 × 300案件/月 = 300,000地点/月）
- `SELECT *`により大量のデータをスキャン
- パーティションは使用されているが、`SELECT *`により効果が限定的

**想定スキャン量**:
- 現在（100案件、100,000地点）: 約300MB/クエリ
- 1年後（3,600案件、3,600,000地点）: 約10.8GB/クエリ
- 3年後（10,800案件、10,800,000地点）: 約32.4GB/クエリ

### 案件サマリの処理

**現状**: フロントエンドで集計処理（`SummaryCards.tsx`など）
- 良い点: BigQueryでの集計クエリを実行していない
- 問題点: 全件取得してからフロントエンドで集計するため、スキャン量は変わらない

## コスト増加の懸念

### 1. 線形増加のリスク

**案件数が増えると**:
- プロジェクト一覧: 案件数に比例してスキャン量が増加
- セグメント一覧: セグメント数に比例してスキャン量が増加
- POI一覧: **地点数に比例して大幅にスキャン量が増加**

**試算**（月間クエリ数は変わらないと仮定）:
- 現在: 約1.3TB/月 → 約270円/月（無料枠1TB適用後）
- 1年後: 約4.7TB/月 → 約2,220円/月（無料枠1TB適用後）
- 3年後: 約14.1TB/月 → 約7,860円/月（無料枠1TB適用後）

### 2. 案件サマリの影響

**現状**: 案件サマリはフロントエンドで集計
- 全件取得してから集計するため、スキャン量は変わらない
- ただし、BigQueryで集計クエリを実行していないため、追加コストは発生していない

**懸念**: 将来的にBigQueryで集計処理を行う場合
- `COUNT`, `SUM`, `GROUP BY`などの集計クエリが追加される可能性
- 集計クエリもスキャン量に応じてコストが発生

## 最適化の推奨事項

### 1. SELECT * を避ける（最重要）

**現状**:
```sql
SELECT * FROM `universegeo_dataset.projects`
```

**最適化後**:
```sql
SELECT 
  project_id,
  project_name,
  advertiser_name,
  project_status,
  _register_datetime,
  created_at,
  updated_at
FROM `universegeo_dataset.projects`
ORDER BY COALESCE(_register_datetime, created_at, updated_at) DESC
```

**効果**:
- スキャン量を約30-50%削減可能
- 必要な列のみ取得することで、ネットワーク転送量も削減

### 2. ページネーションの実装

**現状**: 全件取得

**最適化後**:
```sql
SELECT ...
FROM `universegeo_dataset.projects`
ORDER BY ...
LIMIT 50 OFFSET @offset
```

**効果**:
- 1回のクエリで取得するデータ量を固定
- 案件が増えてもスキャン量が一定

### 3. 集計処理をBigQueryで実行

**現状**: フロントエンドで集計

**最適化後**:
```sql
-- 案件サマリを取得
SELECT 
  project_status,
  COUNT(*) as count
FROM `universegeo_dataset.projects`
GROUP BY project_status
```

**効果**:
- フロントエンドでの処理負荷を削減
- ネットワーク転送量を削減（集計結果のみ転送）
- ただし、スキャン量は変わらない（全件スキャンは必要）

### 4. パーティションプルーニングの活用

**現状**: パーティションは設定済み（`PARTITION BY DATE`）

**最適化後**:
```sql
-- 日付範囲を指定してパーティションプルーニングを活用
SELECT ...
FROM `universegeo_dataset.pois`
WHERE project_id = @project_id
  AND created_at >= @start_date
  AND created_at < @end_date
```

**効果**:
- 必要なパーティションのみスキャン
- スキャン量を大幅に削減可能（例: 1年分のデータから1ヶ月分のみ取得）

### 5. キャッシュの活用

**推奨**:
- 案件一覧: 5分間キャッシュ
- 案件サマリ: 1分間キャッシュ
- セグメント一覧: プロジェクト単位でキャッシュ

**効果**:
- クエリ実行回数を削減
- コスト削減とレスポンス時間の改善

### 6. マテリアライズドビューの検討

**用途**: 案件サマリなどの集計結果を事前計算

```sql
CREATE MATERIALIZED VIEW `universegeo_dataset.project_summary_mv`
AS
SELECT 
  project_status,
  COUNT(*) as count,
  COUNT(DISTINCT project_id) as project_count
FROM `universegeo_dataset.projects`
GROUP BY project_status;
```

**効果**:
- 集計クエリの実行時間を短縮
- ただし、マテリアライズドビュー自体の更新コストが発生

## コスト増加の試算

### 最適化なしの場合

| 期間 | 案件数 | 地点数 | 月間スキャン量 | 月額コスト（無料枠適用後） |
|------|--------|--------|----------------|---------------------------|
| 現在 | 100 | 100,000 | 1.3TB | 約270円 |
| 1年後 | 3,600 | 3,600,000 | 4.7TB | 約2,220円 |
| 3年後 | 10,800 | 10,800,000 | 14.1TB | 約7,860円 |

### 最適化ありの場合（SELECT * を避ける + ページネーション）

| 期間 | 案件数 | 地点数 | 月間スキャン量 | 月額コスト（無料枠適用後） |
|------|--------|--------|----------------|---------------------------|
| 現在 | 100 | 100,000 | 0.65TB | 無料（無料枠内） |
| 1年後 | 3,600 | 3,600,000 | 2.35TB | 約810円 |
| 3年後 | 10,800 | 10,800,000 | 7.05TB | 約3,630円 |

**削減効果**: 約50-60%のコスト削減

### 最適化ありの場合（SELECT * を避ける + ページネーション + パーティションプルーニング）

| 期間 | 案件数 | 地点数 | 月間スキャン量 | 月額コスト（無料枠適用後） |
|------|--------|--------|----------------|---------------------------|
| 現在 | 100 | 100,000 | 0.65TB | 無料（無料枠内） |
| 1年後 | 3,600 | 3,600,000 | 1.2TB | 約120円 |
| 3年後 | 10,800 | 10,800,000 | 3.6TB | 約1,560円 |

**削減効果**: 約70-80%のコスト削減

## 特に注意すべき点

### 1. POIテーブルのスキャン量

**最大のコスト要因**:
- POIテーブルは最も大きくなる（1案件あたり1,000地点）
- `SELECT *`により大量のデータをスキャン
- 案件が増えると指数関数的にスキャン量が増加

**対策**:
- 必要な列のみ選択
- ページネーションの実装
- パーティションプルーニングの活用
- プロジェクトIDやセグメントIDでのフィルタリング

### 2. 案件サマリの集計処理

**現状**: フロントエンドで集計（追加コストなし）

**将来的な懸念**:
- BigQueryで集計処理を行う場合、スキャン量に応じてコストが発生
- ただし、集計結果のみを転送するため、ネットワーク転送量は削減

**推奨**:
- 集計処理はBigQueryで実行（スキャン量は変わらないが、転送量を削減）
- マテリアライズドビューの検討（更新コストとのトレードオフ）

### 3. 無料枠の活用

**BigQuery無料枠**:
- クエリ: 最初の1TB/月は無料
- ストレージ: 最初の10GB/月は無料

**推奨**:
- 最適化により無料枠内で運用可能な期間を延長
- 無料枠を超過する場合は、予算アラートを設定

## 実装優先度

### 高優先度（即座に実装推奨）

1. **SELECT * を避ける**
   - 効果: 50-60%のコスト削減
   - 実装難易度: 低
   - 影響範囲: 全クエリ

2. **ページネーションの実装**
   - 効果: スキャン量の固定化
   - 実装難易度: 中
   - 影響範囲: 一覧取得クエリ

### 中優先度（1-3ヶ月以内に実装推奨）

3. **パーティションプルーニングの活用**
   - 効果: 70-80%のコスト削減
   - 実装難易度: 中
   - 影響範囲: 日付範囲指定クエリ

4. **キャッシュの活用**
   - 効果: クエリ実行回数の削減
   - 実装難易度: 低
   - 影響範囲: 一覧取得、サマリ取得

### 低優先度（必要に応じて実装）

5. **マテリアライズドビューの検討**
   - 効果: 集計クエリの高速化
   - 実装難易度: 高
   - 影響範囲: 集計処理

6. **集計処理をBigQueryで実行**
   - 効果: 転送量の削減
   - 実装難易度: 中
   - 影響範囲: サマリ取得

## 監視とアラート

### 推奨監視項目

1. **月間スキャン量**
   - 目標: 1TB/月以内（無料枠内）
   - アラート: 1.5TB/月を超過した場合

2. **クエリ実行回数**
   - 目標: 月間50,000回以内
   - アラート: 月間100,000回を超過した場合

3. **平均スキャン量/クエリ**
   - 目標: 20MB/クエリ以内
   - アラート: 50MB/クエリを超過した場合

### GCP予算アラートの設定

1. BigQuery予算: 月額5,000円
2. 全体予算: 月額10,000円
3. アラート閾値: 50%, 90%, 100%

## その他のコスト削減方法

### 7. データ保持期間の最適化（テーブル有効期限の設定）

**現状**: データが無期限に保持される

**最適化後**:
```sql
-- テーブルに有効期限を設定（例: 3年後）
ALTER TABLE `universegeo_dataset.pois`
SET OPTIONS(
  expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 3 YEAR)
);

-- または、パーティション単位で有効期限を設定
ALTER TABLE `universegeo_dataset.pois`
SET OPTIONS(
  partition_expiration_days=1095  -- 3年 = 1095日
);
```

**効果**:
- 古いデータが自動的に削除され、ストレージコストを削減
- 3年保持の場合: 約99円/月 → 約33円/月（3年で削除）

**推奨設定**:
- **POIテーブル**: 3年（データ連携後3年で削除）
- **プロジェクトテーブル**: 5年（長期保持）
- **セグメントテーブル**: 3年（プロジェクトと同期）
- **変更履歴テーブル**: 1年（短期保持）

### 8. データアーカイブ戦略

**用途**: 古いデータを低コストストレージに移動

**方法1: Cloud Storageへのエクスポート**
```sql
-- 3年以上古いデータをCloud Storageにエクスポート
EXPORT DATA OPTIONS(
  uri='gs://universegeo-archive/pois_2020/*.json',
  format='JSON'
) AS
SELECT *
FROM `universegeo_dataset.pois`
WHERE created_at < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 3 YEAR);
```

**方法2: 別テーブルへの移動**
```sql
-- アーカイブ用テーブルを作成
CREATE TABLE `universegeo_dataset.pois_archive`
LIKE `universegeo_dataset.pois`;

-- 古いデータを移動
INSERT INTO `universegeo_dataset.pois_archive`
SELECT * FROM `universegeo_dataset.pois`
WHERE created_at < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 3 YEAR);

-- 元のテーブルから削除
DELETE FROM `universegeo_dataset.pois`
WHERE created_at < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 3 YEAR);
```

**効果**:
- ストレージコスト: $0.020/GB-月 → $0.004/GB-月（Coldline Storage）
- 約80%のストレージコスト削減

### 9. クラスタリングの活用

**用途**: クエリパフォーマンス向上とスキャン量削減

**最適化後**:
```sql
-- POIテーブルにクラスタリングを追加
CREATE TABLE `universegeo_dataset.pois`
(
  -- フィールド定義...
)
PARTITION BY DATE(created_at)
CLUSTER BY project_id, segment_id
OPTIONS(
  description="POI（地点）情報"
);
```

**効果**:
- `project_id`や`segment_id`でのフィルタリング時にスキャン量を削減
- クエリパフォーマンスの向上
- コスト削減: 約10-30%

**推奨クラスタリング**:
- **POIテーブル**: `project_id`, `segment_id`
- **セグメントテーブル**: `project_id`
- **プロジェクトテーブル**: `project_status`

### 10. クエリ結果キャッシュの活用

**現状**: クエリ結果がキャッシュされていない可能性

**最適化後**:
```typescript
// クエリオプションにキャッシュ設定を追加
const queryOptions = {
  query: query,
  useQueryCache: true,  // クエリ結果キャッシュを有効化
  useLegacySql: false,
};
```

**効果**:
- 同じクエリを24時間以内に再実行した場合、スキャン量が0
- 案件一覧などの頻繁に実行されるクエリで効果大
- コスト削減: 約20-40%（キャッシュヒット率による）

### 11. ストリーミングインサートの最適化

**現状**: バッチインサートを使用

**最適化後**:
```typescript
// ストリーミングインサートを使用（リアルタイム性が必要な場合）
await table.insert(rows, {
  skipInvalidRows: true,
  ignoreUnknownValues: true,
  rawInsertIds: true,  // 重複チェックを有効化
});
```

**効果**:
- バッチ処理のオーバーヘッドを削減
- ただし、ストリーミングインサートは追加コストが発生（$0.01/200MB）

**推奨**:
- リアルタイム性が不要な場合: バッチインサートを継続
- リアルタイム性が必要な場合: ストリーミングインサートを検討

### 12. 外部データソースの活用（Cloud Storage）

**用途**: 頻繁にアクセスしないデータをCloud Storageに保存

**方法**:
```sql
-- 外部テーブルを作成
CREATE EXTERNAL TABLE `universegeo_dataset.pois_external`
OPTIONS (
  format='JSON',
  uris=['gs://universegeo-data/pois/*.json']
);
```

**効果**:
- ストレージコスト: $0.020/GB-月 → $0.023/GB-月（Standard Storage）
- ただし、クエリ時にデータを読み込むため、クエリコストは変わらない
- アーカイブデータの保存に適している

### 13. 不要なデータの削除

**現状**: 削除されたデータが残っている可能性

**最適化後**:
```sql
-- 論理削除フラグがある場合、物理削除を実行
DELETE FROM `universegeo_dataset.pois`
WHERE deleted_at IS NOT NULL
  AND deleted_at < TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 90 DAY);
```

**効果**:
- ストレージコストの削減
- クエリスキャン量の削減

### 14. テーブルの統合・分割の検討

**現状**: 各エンティティごとにテーブルが分かれている

**検討事項**:
- **統合**: 関連データを1つのテーブルに統合（JOINの削減）
- **分割**: 大きなテーブルを分割（パーティションの効果を最大化）

**例: プロジェクト+セグメントの統合**
```sql
-- プロジェクトとセグメントを統合（非推奨: 正規化の原則に反する）
-- ただし、特定のクエリパターンでは効果的
```

**推奨**: 現在のテーブル設計を維持（正規化されている）

### 15. クエリの実行計画の最適化

**方法**: クエリの実行計画を確認して最適化

```sql
-- クエリの実行計画を確認
EXPLAIN SELECT ...
FROM `universegeo_dataset.pois`
WHERE project_id = 'PRJ-1';
```

**最適化のポイント**:
- パーティションプルーニングが機能しているか確認
- クラスタリングが効果的に機能しているか確認
- 不要なJOINやサブクエリの削減

### 16. 並列処理の活用

**現状**: シーケンシャルにクエリを実行

**最適化後**:
```typescript
// 複数のクエリを並列実行
const [projects, segments, pois] = await Promise.all([
  getProjects(),
  getSegments(),
  getPois(),
]);
```

**効果**:
- クエリ実行時間の短縮
- コストは変わらないが、ユーザー体験が向上

### 17. データ圧縮の活用

**BigQueryの自動圧縮**:
- BigQueryは自動的にデータを圧縮（約10:1の圧縮率）
- ストレージコストは圧縮後のサイズで課金

**効果**:
- 既に自動的に適用されている
- 追加の設定は不要

### 18. バッチ処理の最適化

**現状**: リアルタイム処理

**最適化後**:
```typescript
// バッチ処理で複数の操作をまとめて実行
const batchOperations = [
  { type: 'insert', data: newPois },
  { type: 'update', data: updatedPois },
  { type: 'delete', data: deletedPoiIds },
];

// 1回のトランザクションで実行
await executeBatchOperations(batchOperations);
```

**効果**:
- クエリ実行回数の削減
- トランザクションコストの削減

### 19. インデックスの最適化（将来的に）

**注意**: BigQueryは自動的にインデックスを管理

**将来的な検討事項**:
- 検索インデックス（Search Index）の活用
- ベクトル検索（Vector Search）の活用

### 20. モニタリングとアラートの強化

**推奨監視項目**:
1. **クエリコスト**: 月間スキャン量、平均スキャン量/クエリ
2. **ストレージコスト**: テーブルサイズ、データ増加率
3. **クエリパフォーマンス**: 実行時間、スロット使用量
4. **エラー率**: 失敗したクエリの割合

**アラート設定**:
```yaml
# GCP予算アラート
budget_amount: 10000  # 月額10,000円
alert_thresholds:
  - percentage: 50
  - percentage: 90
  - percentage: 100
```

### 21. クエリの最適化チェックリスト

**実装前の確認事項**:
- [ ] `SELECT *` を避け、必要な列のみ選択
- [ ] パーティションプルーニングが機能しているか確認
- [ ] クラスタリングが効果的に機能しているか確認
- [ ] 不要なJOINやサブクエリを削減
- [ ] クエリ結果キャッシュを有効化
- [ ] ページネーションを実装
- [ ] 日付範囲を指定してパーティションプルーニングを活用

### 22. コスト削減の優先順位（総合）

| 優先度 | 最適化方法 | 効果 | 実装難易度 | 実装時間 |
|--------|-----------|------|-----------|---------|
| 高 | SELECT * を避ける | 50-60%削減 | 低 | 1-2日 |
| 高 | ページネーション | スキャン量固定化 | 中 | 3-5日 |
| 中 | パーティションプルーニング | 70-80%削減 | 中 | 2-3日 |
| 中 | データ保持期間の最適化 | ストレージ削減 | 低 | 1日 |
| 中 | クエリ結果キャッシュ | 20-40%削減 | 低 | 1日 |
| 中 | クラスタリング | 10-30%削減 | 中 | 2-3日 |
| 低 | データアーカイブ | ストレージ80%削減 | 高 | 5-10日 |
| 低 | マテリアライズドビュー | 集計高速化 | 高 | 3-5日 |

## 総合的なコスト削減効果

### 最適化なしの場合

| 期間 | 案件数 | 地点数 | クエリコスト | ストレージコスト | 合計 |
|------|--------|--------|------------|----------------|------|
| 現在 | 100 | 100,000 | 270円 | 33円 | 303円 |
| 1年後 | 3,600 | 3,600,000 | 2,220円 | 33円 | 2,253円 |
| 3年後 | 10,800 | 10,800,000 | 7,860円 | 99円 | 7,959円 |

### 最適化ありの場合（高優先度のみ実装）

| 期間 | 案件数 | 地点数 | クエリコスト | ストレージコスト | 合計 | 削減率 |
|------|--------|--------|------------|----------------|------|--------|
| 現在 | 100 | 100,000 | 0円（無料枠内） | 33円 | 33円 | 89% |
| 1年後 | 3,600 | 3,600,000 | 120円 | 33円 | 153円 | 93% |
| 3年後 | 10,800 | 10,800,000 | 1,560円 | 33円 | 1,593円 | 80% |

### 最適化ありの場合（全項目実装）

| 期間 | 案件数 | 地点数 | クエリコスト | ストレージコスト | 合計 | 削減率 |
|------|--------|--------|------------|----------------|------|--------|
| 現在 | 100 | 100,000 | 0円（無料枠内） | 33円 | 33円 | 89% |
| 1年後 | 3,600 | 3,600,000 | 60円 | 20円 | 80円 | 96% |
| 3年後 | 10,800 | 10,800,000 | 780円 | 20円 | 800円 | 90% |

**総合削減効果**: 約80-96%のコスト削減

## 参考資料

- [BigQuery料金](https://cloud.google.com/bigquery/pricing)
- [BigQuery最適化ガイド](https://cloud.google.com/bigquery/docs/best-practices-costs)
- [パーティションプルーニング](https://cloud.google.com/bigquery/docs/partitioned-tables)
- [クラスタリング](https://cloud.google.com/bigquery/docs/clustered-tables)
- [クエリ結果キャッシュ](https://cloud.google.com/bigquery/docs/cached-results)
- [データ保持期間の設定](https://cloud.google.com/bigquery/docs/managing-tables#set_expiration)
